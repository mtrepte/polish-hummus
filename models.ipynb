{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans(X, y):\n",
    "    # hyperparameters\n",
    "    n_dim = 2\n",
    "    \n",
    "    # label color mapping\n",
    "    labels = ['hate', 'chill']\n",
    "    colors = ['red', 'blue']\n",
    "    \n",
    "    # apply PCA to featurized tweets\n",
    "    X = PCA(n_components=n_dim).fit_transform(X)\n",
    "\n",
    "    # plot data\n",
    "    for i in range(len(X)):\n",
    "        x, y = X[i, 0], X[i, 1]\n",
    "        plt.scatter(x, y, c=colors[y], cmap=plt.cm.Paired)\n",
    "\n",
    "    # legend\n",
    "    patches = [mpatches.Patch(color=colors[i], label=labels[i]) for i in range(len(labels))]\n",
    "    plt.legend(handles=patches, loc=locs[j], fontsize=10)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest(X, y):\n",
    "    # partition dataset\n",
    "    training_percent = .70\n",
    "    partition_index = int(training_percent * len(X))\n",
    "    X_train = X[:partition_index]\n",
    "    X_test = X[partition_index:]\n",
    "    y_train = y[:partition_index]\n",
    "    y_test = y[partition_index:]\n",
    "    \n",
    "    # hyperparameters\n",
    "    forests_num = 20\n",
    "    \n",
    "    # train\n",
    "    random_forest = RandomForestClassifier(n_estimators=forests_num)\n",
    "    random_forest.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    length = len(X_test)\n",
    "    X_predicts = [random_forest.predict(X_test[i], y_test[i]) for i in length]\n",
    "    \n",
    "    return X_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn(X, y):\n",
    "    #hyperparameters\n",
    "    look_back = 1\n",
    "    \n",
    "    # normalizing featurized tweets\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scalar.fit_transform(X)\n",
    "    \n",
    "    # partition dataset\n",
    "    training_percent = .70\n",
    "    partition_index = int(training_percent * len(X))\n",
    "    X_train = X[:partition_index]\n",
    "    X_test = X[partition_index:]\n",
    "    y_train = y[:partition_index]\n",
    "    y_test = y[partition_index:]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
